#!/usr/bin/env python3
"""
è§†é¢‘è·³è½¬æ£€æµ‹å™¨ - å¸¦å®æ—¶è¿›åº¦æ˜¾ç¤º
ä½¿ç”¨"å»æŠ– + å¸§å·®èƒ½é‡ + å¼‚å¸¸å€¼æ£€æµ‹"å¿«é€Ÿæ‰¾å‡ºè§†é¢‘ä¸­çš„è·³è½¬ç‚¹
"""

import cv2
import numpy as np
import json
import os
import time
from pathlib import Path
from tqdm import tqdm

def robust_zscore(x, eps=1e-9):
    """
    è®¡ç®—é²æ£’Zåˆ†æ•°ï¼ˆä½¿ç”¨MADï¼‰
    """
    x = np.asarray(x, dtype=np.float32)
    med = np.median(x)
    mad = np.median(np.abs(x - med)) + eps
    z = 0.6745 * (x - med) / mad
    return z, med, mad

def detect_jumps(video_path, z_th=6.0, min_gap=8, use_align=True, max_frames=None):
    """
    æ£€æµ‹è§†é¢‘ä¸­çš„è·³è½¬ç‚¹

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        z_th: Zåˆ†æ•°é˜ˆå€¼ï¼ˆé»˜è®¤6.0ï¼‰
        min_gap: æœ€å°é—´éš”å¸§æ•°ï¼ˆé˜²æ­¢è¿ç»­æ£€æµ‹ï¼‰
        use_align: æ˜¯å¦ä½¿ç”¨å…¨å±€å¯¹é½ï¼ˆæŠµæ¶ˆæŠ–åŠ¨ï¼‰
        max_frames: æœ€å¤§å¤„ç†å¸§æ•°ï¼ˆNoneè¡¨ç¤ºå¤„ç†å…¨éƒ¨ï¼‰

    Returns:
        result: è·³è½¬ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªåŒ…å«frame, time_sec, score, z
        scores: æ‰€æœ‰å¸§çš„å˜åŒ–åˆ†æ•°
        z: æ‰€æœ‰å¸§çš„Zåˆ†æ•°
    """
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0

    # è·å–æ€»å¸§æ•°ç”¨äºè¿›åº¦æ¡
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    if max_frames and max_frames < total_frames:
        total_frames = max_frames

    print(f"è§†é¢‘ä¿¡æ¯: FPS={fps:.2f}, æ€»å¸§æ•°={total_frames}")

    # ORBç‰¹å¾æ£€æµ‹å™¨
    orb = cv2.ORB_create(800)
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

    scores = []
    prev_gray = None
    prev_kp, prev_des = None, None

    idx = 0

    # åˆ›å»ºè¿›åº¦æ¡
    pbar = tqdm(total=total_frames, desc="ğŸ” æ£€æµ‹è·³è½¬ç‚¹", unit="å¸§", ncols=100)

    start_time = time.time()
    last_update = start_time

    while True:
        ok, frame = cap.read()
        if not ok:
            break
        idx += 1
        if max_frames and idx > max_frames:
            break

        # è½¬æ¢ä¸ºç°åº¦å›¾å¹¶æ¨¡ç³Š
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        gray = cv2.GaussianBlur(gray, (5, 5), 0)

        if prev_gray is None:
            prev_gray = gray
            prev_kp, prev_des = orb.detectAndCompute(prev_gray, None)
            scores.append(0.0)
            pbar.update(1)
            continue

        cur = gray

        # 1) å…¨å±€å¯¹é½ï¼ˆæŠµæ¶ˆæŠ–åŠ¨ï¼‰
        if use_align and prev_des is not None:
            kp, des = orb.detectAndCompute(cur, None)
            if des is not None and len(des) > 20 and prev_des is not None and len(prev_des) > 20:
                matches = bf.match(prev_des, des)
                matches = sorted(matches, key=lambda m: m.distance)[:120]

                if len(matches) >= 12:
                    pts_prev = np.float32([prev_kp[m.queryIdx].pt for m in matches])
                    pts_cur  = np.float32([kp[m.trainIdx].pt for m in matches])

                    # ä»¿å°„å˜æ¢
                    M, inliers = cv2.estimateAffinePartial2D(
                        pts_cur, pts_prev, method=cv2.RANSAC, ransacReprojThreshold=3.0
                    )
                    if M is not None:
                        cur = cv2.warpAffine(cur, M, (cur.shape[1], cur.shape[0]),
                                           flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)
            prev_kp, prev_des = kp, des

        # 2) å¸§å·®åˆ†æ•°ï¼šå˜åŒ–åƒç´ å æ¯”
        diff = cv2.absdiff(cur, prev_gray)
        _, bw = cv2.threshold(diff, 25, 255, cv2.THRESH_BINARY)  # é˜ˆå€¼å¯è°ƒ
        score = float(bw.mean())  # 0~255
        scores.append(score)

        prev_gray = cur

        # æ›´æ–°è¿›åº¦æ¡
        pbar.update(1)

        # æ¯ç§’æ›´æ–°ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
        current_time = time.time()
        if current_time - last_update >= 1.0:
            elapsed = current_time - start_time
            fps_current = idx / elapsed if elapsed > 0 else 0
            eta = (total_frames - idx) / fps_current if fps_current > 0 else 0
            percent = (idx / total_frames) * 100

            pbar.set_postfix({
                'FPS': f"{fps_current:.1f}",
                'ETA': f"{eta:.1f}s",
                'è¿›åº¦': f"{percent:.1f}%",
                'å¸§': f"{idx}/{total_frames}"
            })
            last_update = current_time

    pbar.close()
    cap.release()

    # 3) é²æ£’å¼‚å¸¸æ£€æµ‹
    print("\nğŸ“Š åˆ†æå˜åŒ–åˆ†æ•°...")
    z, med, mad = robust_zscore(scores)
    candidates = np.where(z > z_th)[0].tolist()

    # 4) å»é‡ï¼šåªä¿ç•™ç›¸éš”min_gapå¸§ä»¥ä¸Šçš„ç‚¹
    jumps = []
    last = -10**9
    for t in candidates:
        if t - last >= min_gap:
            jumps.append(t)
            last = t

    # è¾“å‡ºï¼šå¸§å· + æ—¶é—´ç‚¹ï¼ˆç§’ï¼‰
    result = [{"frame": t, "time_sec": t / fps, "score": scores[t], "z": float(z[t])} for t in jumps]
    return result, scores, z

def save_keyframes(video_path, jump_frames, output_dir="keyframes"):
    """
    ä¿å­˜å…³é”®å¸§å›¾åƒ
    """
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0

    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path(output_dir).mkdir(exist_ok=True)

    print(f"\nğŸ’¾ ä¿å­˜å…³é”®å¸§å›¾åƒåˆ°ç›®å½•: {output_dir}")

    # åˆ›å»ºè¿›åº¦æ¡
    pbar = tqdm(total=len(jump_frames), desc="ğŸ“¸ ä¿å­˜å…³é”®å¸§", unit="å¼ ", ncols=80)

    for i, jump in enumerate(jump_frames):
        frame_idx = jump['frame']
        time_sec = jump['time_sec']

        # è·³è½¬åˆ°æŒ‡å®šå¸§
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
        ret, frame = cap.read()

        if ret:
            # ç”Ÿæˆæ–‡ä»¶åï¼šjump_åºå·_æ—¶é—´æˆ³_å¸§å·.jpg
            filename = f"jump_{i+1:03d}_{time_sec:.2f}s_frame{frame_idx:06d}.jpg"
            filepath = os.path.join(output_dir, filename)

            # ä¿å­˜å›¾åƒ
            cv2.imwrite(filepath, frame)
            pbar.set_postfix({'æ–‡ä»¶': filename[:30]})

        pbar.update(1)

    pbar.close()
    cap.release()

def main():
    video_path = "1ad0f046c0dd45f09797593a9db7a294.mp4"

    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(video_path):
        print(f"âŒ é”™è¯¯: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        return

    print("="*70)
    print("ğŸ¬ è§†é¢‘è·³è½¬æ£€æµ‹å™¨ - å¸¦å®æ—¶è¿›åº¦æ˜¾ç¤º")
    print("="*70)
    print(f"ğŸ“¹ å¤„ç†è§†é¢‘: {video_path}")

    # è·å–è§†é¢‘ä¿¡æ¯
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS) or 30.0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = total_frames / fps
    cap.release()

    print(f"ğŸ“Š è§†é¢‘ä¿¡æ¯: FPS={fps:.2f}, æ€»å¸§æ•°={total_frames}, æ—¶é•¿={duration:.2f}ç§’")

    # è®¡ç®—è¦å¤„ç†çš„å¸§æ•°ï¼ˆå–å‰1åˆ†é’Ÿï¼‰
    max_frames = int(fps * 60)  # å‰60ç§’
    if max_frames > total_frames:
        max_frames = total_frames

    print(f"â±ï¸  å¤„ç†å‰ {max_frames} å¸§ (å‰ {max_frames/fps:.1f} ç§’)")

    # æ‰§è¡Œè·³è½¬æ£€æµ‹
    print("\nğŸš€ å¼€å§‹æ£€æµ‹è·³è½¬ç‚¹...")
    start_time = time.time()

    result, scores, z = detect_jumps(
        video_path,
        z_th=6.0,      # Zåˆ†æ•°é˜ˆå€¼
        min_gap=8,     # æœ€å°é—´éš”8å¸§
        use_align=True,  # å¯ç”¨å…¨å±€å¯¹é½
        max_frames=max_frames
    )

    elapsed_time = time.time() - start_time
    print(f"\nâ±ï¸  æ£€æµ‹å®Œæˆ! è€—æ—¶ {elapsed_time:.2f} ç§’")

    print(f"\nğŸ¯ æ£€æµ‹ç»“æœ: å‘ç° {len(result)} ä¸ªè·³è½¬ç‚¹:")
    print("-" * 70)

    if result:
        for i, jump in enumerate(result):
            print(f"{i+1:2d}. å¸§{jump['frame']:6d} | "
                  f"â° æ—¶é—´{jump['time_sec']:6.2f}s | "
                  f"ğŸ“ˆ åˆ†æ•°{jump['score']:6.2f} | "
                  f"ğŸ”¢ Zå€¼{jump['z']:6.2f}")
    else:
        print("âŒ æœªæ£€æµ‹åˆ°ä»»ä½•è·³è½¬ç‚¹")

    # ä¿å­˜JSONç»“æœ
    output_data = {
        "video_file": video_path,
        "video_info": {
            "fps": fps,
            "total_frames": total_frames,
            "duration_sec": duration,
            "processed_frames": max_frames
        },
        "detection_params": {
            "z_threshold": 6.0,
            "min_gap_frames": 8,
            "use_alignment": True
        },
        "jumps": result,
        "statistics": {
            "total_jumps": len(result),
            "avg_score": float(np.mean([j['score'] for j in result])) if result else 0,
            "avg_z": float(np.mean([j['z'] for j in result])) if result else 0,
            "processing_time_sec": elapsed_time
        }
    }

    json_path = "jump_detection_results.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… JSONç»“æœå·²ä¿å­˜åˆ°: {json_path}")

    # ä¿å­˜å…³é”®å¸§å›¾åƒ
    if result:
        save_keyframes(video_path, result, "keyframes")
        print("\nâœ… æ‰€æœ‰å…³é”®å¸§å·²ä¿å­˜å®Œæˆ!")
    else:
        print("\nâš ï¸  æœªæ£€æµ‹åˆ°è·³è½¬ç‚¹ï¼Œè·³è¿‡å…³é”®å¸§ä¿å­˜")

    print("\n" + "="*70)
    print("âœ¨ å¤„ç†å®Œæˆ!")
    print("="*70)

if __name__ == "__main__":
    main()
